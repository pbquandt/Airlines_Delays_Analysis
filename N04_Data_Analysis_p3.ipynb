{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GSGpg7lciSr0"
   },
   "source": [
    " # Opis notatnika\n",
    " Zmierzamy do końca analizy danych, które zostały nam udostępnione. Ten krok dodaje jeszcze więcej informacji do naszego wyjściowego zbioru. Tym razem sprawdzimy między innymi to, czy opóźnienia lotów zależne są od trasy czy warunków pogodowych.\n",
    "\n",
    " Zanim jednak do tego przejdziemy, należy, podobnie jak w poprzednich krokach, skonfigurować odpowiednio notatnik."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bF88obm2iSr4"
   },
   "source": [
    " Tutaj zaimportuj wymagane biblioteki"
   ]
  },
  {
   "cell_type": "code",
   "metadata": {
    "id": "UuQtAJAOiSr5",
    "ExecuteTime": {
     "end_time": "2024-11-22T08:39:36.039791Z",
     "start_time": "2024-11-22T08:39:35.492496Z"
    }
   },
   "source": [
    "import psycopg2\n",
    "from psycopg2 import connect\n",
    "import pandas as pd\n",
    "from sqlalchemy import create_engine\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.stats import ttest_ind\n",
    "from scipy.stats import f_oneway"
   ],
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'scipy'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mModuleNotFoundError\u001B[0m                       Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 7\u001B[0m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mmatplotlib\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mpyplot\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mplt\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;28;01mimport\u001B[39;00m \u001B[38;5;21;01mnumpy\u001B[39;00m \u001B[38;5;28;01mas\u001B[39;00m \u001B[38;5;21;01mnp\u001B[39;00m\n\u001B[0;32m----> 7\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m ttest_ind\n\u001B[1;32m      8\u001B[0m \u001B[38;5;28;01mfrom\u001B[39;00m \u001B[38;5;21;01mscipy\u001B[39;00m\u001B[38;5;21;01m.\u001B[39;00m\u001B[38;5;21;01mstats\u001B[39;00m \u001B[38;5;28;01mimport\u001B[39;00m f_oneway\n",
      "\u001B[0;31mModuleNotFoundError\u001B[0m: No module named 'scipy'"
     ]
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "WRSC_2ogiSr6"
   },
   "source": [
    " ## Połączenie z bazą danych\n",
    " Tutaj uzupełnij konfigurację połączenia"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "444G833ciSr7"
   },
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "             host='localhost',\n",
    "             user='postgres', \n",
    "             password='p',\n",
    "             dbname='airlines'  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = connect(host='localhost', database='airlines', user='postgres', password='p')\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IlQvHCwHiSr7"
   },
   "source": [
    " Tutaj stwórz zmienną engine, która zostanie użyta do połączenia z bazą danych"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "uczM1OVWiSr8"
   },
   "outputs": [],
   "source": [
    "url = f'postgresql://postgres:p@localhost/flight'\n",
    "engine = create_engine(url)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3OUYFIwLiSr8"
   },
   "source": [
    " Tutaj uzupełnij implementację metody `read_sql_table`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "X5HAtWUGiSr9"
   },
   "outputs": [],
   "source": [
    "def read_sql_table(table_name):\n",
    "    query = f\"SELECT * FROM {table_name}\"\n",
    "    cursor = connection.cursor()\n",
    "    cursor.execute(query)\n",
    "    column_names = [desc[0] for desc in cursor.description]\n",
    "    results = cursor.fetchall()\n",
    "    cursor.close()\n",
    "    connection.close()\n",
    "    df = pd.DataFrame(results, columns=column_names)   \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "s5VOVS0DiSr-"
   },
   "source": [
    " Tutaj zaczytaj zapisaną wcześniej ramkę danych `flight_df` do zmniennej o takiej samej nazwie"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "1qkBzo5QiSr-"
   },
   "outputs": [],
   "source": [
    "flight_df = pd.read_csv(\"/Users/Me/Desktop/Airports_CL/data/processed/flight_df_02.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "npSQe2AriSr-"
   },
   "source": [
    " # Wzbogacenie o `airport_list`\n",
    " Wczytaj do obszaru roboczego tabelę `airport_list` używając procedury `read_sql_table`. Wykonaj poniższe ćwiczenia:\n",
    " 1. Sprawdź, czy klucz `origin_airport_id` jest unikalny, tj. nie ma dwóch takich samych wartości w kolumnie `origin_airport_id`,\n",
    " 1. Jeżeli duplikaty występują, usuń je w najdogodniejszy dla Ciebie sposób.\n",
    " 1. Jeśli duplikaty nie występują, złącz ramki `airport_list_df` wraz z aktualną `flight_df`, używając kolumny `origin_airport_id` oraz złączenia typu `LEFT JOIN`. Z ramki `airport_list_df` interesuje nas dodanie kolumny `origin_city_name`.\n",
    " 1. Dodatkowo dokonaj jeszcze raz złączenia ramki `flight_df` z `airport_list_df`, tym razem jednak złącz kolumnę `destination_airport_id` wraz z `origin_airport_id`. Podobnie jak wcześniej, interesuje nas kolumna `origin_city_name`, jedank ona powinna zostać wyświetlona jako `destination_city_name`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "f1ujavbmiSr_"
   },
   "source": [
    " Tutaj wczytaj ramkę `airport_list_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "NqU5iI3kiSsA"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 97 entries, 0 to 96\n",
      "Data columns (total 5 columns):\n",
      " #   Column                Non-Null Count  Dtype \n",
      "---  ------                --------------  ----- \n",
      " 0   id                    97 non-null     int64 \n",
      " 1   origin_airport_id     97 non-null     int64 \n",
      " 2   display_airport_name  97 non-null     object\n",
      " 3   origin_city_name      97 non-null     object\n",
      " 4   name                  97 non-null     object\n",
      "dtypes: int64(2), object(3)\n",
      "memory usage: 3.9+ KB\n"
     ]
    }
   ],
   "source": [
    "airport_list_df = read_sql_table('airport_list')\n",
    "airport_list_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y7BoIO66iSsA"
   },
   "source": [
    " Tutaj sprawdż, czy występują duplikaty dla kolumny `origin_airport_id`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NO2RzpYDiSsA"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    97\n",
       "Name: origin_airport_id, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "duplikaty = airport_list_df['origin_airport_id'].duplicated()\n",
    "duplikaty.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mRoPbkefiSsA"
   },
   "source": [
    " Tutaj usuń duplikaty - jeśli występują"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sdDW1fcDiSsB"
   },
   "source": [
    "#nie ma duplikatów"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lay6tlPSiSsB"
   },
   "source": [
    " Tutaj dokonaj złączenia ramki `flight_df` oraz `airport_list_df` używając `origin_airport_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#przed złączeniem"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6922924 entries, 0 to 6922923\n",
      "Data columns (total 33 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   id                    int64  \n",
      " 1   month                 int64  \n",
      " 2   day_of_month          int64  \n",
      " 3   day_of_week           int64  \n",
      " 4   op_unique_carrier     object \n",
      " 5   tail_num              object \n",
      " 6   op_carrier_fl_num     int64  \n",
      " 7   origin_airport_id     int64  \n",
      " 8   dest_airport_id       int64  \n",
      " 9   crs_dep_time          int64  \n",
      " 10  dep_time              float64\n",
      " 11  dep_delay             float64\n",
      " 12  dep_time_blk          object \n",
      " 13  crs_arr_time          int64  \n",
      " 14  arr_time              float64\n",
      " 15  arr_delay_new         float64\n",
      " 16  arr_time_blk          object \n",
      " 17  cancelled             int64  \n",
      " 18  crs_elapsed_time      float64\n",
      " 19  actual_elapsed_time   float64\n",
      " 20  distance              int64  \n",
      " 21  distance_group        int64  \n",
      " 22  year                  int64  \n",
      " 23  carrier_delay         float64\n",
      " 24  weather_delay         float64\n",
      " 25  nas_delay             float64\n",
      " 26  security_delay        float64\n",
      " 27  late_aircraft_delay   float64\n",
      " 28  is_delayed            bool   \n",
      " 29  is_weekend            bool   \n",
      " 30  distance_agg          object \n",
      " 31  manufacture_year      int64  \n",
      " 32  manufacture_year_agg  int64  \n",
      "dtypes: bool(2), float64(11), int64(15), object(5)\n",
      "memory usage: 1.6+ GB\n"
     ]
    }
   ],
   "source": [
    "flight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#po złączeniu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6922924 entries, 0 to 6922923\n",
      "Data columns (total 34 columns):\n",
      " #   Column                Dtype  \n",
      "---  ------                -----  \n",
      " 0   id                    int64  \n",
      " 1   month                 int64  \n",
      " 2   day_of_month          int64  \n",
      " 3   day_of_week           int64  \n",
      " 4   op_unique_carrier     object \n",
      " 5   tail_num              object \n",
      " 6   op_carrier_fl_num     int64  \n",
      " 7   origin_airport_id     int64  \n",
      " 8   dest_airport_id       int64  \n",
      " 9   crs_dep_time          int64  \n",
      " 10  dep_time              float64\n",
      " 11  dep_delay             float64\n",
      " 12  dep_time_blk          object \n",
      " 13  crs_arr_time          int64  \n",
      " 14  arr_time              float64\n",
      " 15  arr_delay_new         float64\n",
      " 16  arr_time_blk          object \n",
      " 17  cancelled             int64  \n",
      " 18  crs_elapsed_time      float64\n",
      " 19  actual_elapsed_time   float64\n",
      " 20  distance              int64  \n",
      " 21  distance_group        int64  \n",
      " 22  year                  int64  \n",
      " 23  carrier_delay         float64\n",
      " 24  weather_delay         float64\n",
      " 25  nas_delay             float64\n",
      " 26  security_delay        float64\n",
      " 27  late_aircraft_delay   float64\n",
      " 28  is_delayed            bool   \n",
      " 29  is_weekend            bool   \n",
      " 30  distance_agg          object \n",
      " 31  manufacture_year      int64  \n",
      " 32  manufacture_year_agg  int64  \n",
      " 33  origin_city_name      object \n",
      "dtypes: bool(2), float64(11), int64(15), object(6)\n",
      "memory usage: 1.7+ GB\n"
     ]
    }
   ],
   "source": [
    "flight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Dodatkowo dokonaj jeszcze raz złączenia ramki flight_df z airport_list_df, tym razem jednak złącz kolumnę destination_airport_id wraz z origin_airport_id. Podobnie jak wcześniej, interesuje nas kolumna origin_city_name, jedank ona powinna zostać wyświetlona jako destination_city_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5AcIjdrSiSsB"
   },
   "source": [
    "Tutaj dokonaj złączenia ramki `flight_df` oraz `airport_list_df` używając `destination_airport_id`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#Tu coś nie pasowało, i okazało się, że 'destination_airport_id' nazywa się 'dest_airport_id'. Zatem zmieniełem nazwe na tą wymaganą w zadaniu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = flight_df.rename(columns={'dest_airport_id': 'destination_airport_id'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = pd.merge(flight_df, airport_list_df[['origin_airport_id', 'origin_city_name']],\n",
    "                     left_on='destination_airport_id', right_on='origin_airport_id', how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#ramka po złączeniu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6922924 entries, 0 to 6922923\n",
      "Data columns (total 36 columns):\n",
      " #   Column                  Dtype  \n",
      "---  ------                  -----  \n",
      " 0   id                      int64  \n",
      " 1   month                   int64  \n",
      " 2   day_of_month            int64  \n",
      " 3   day_of_week             int64  \n",
      " 4   op_unique_carrier       object \n",
      " 5   tail_num                object \n",
      " 6   op_carrier_fl_num       int64  \n",
      " 7   origin_airport_id_x     int64  \n",
      " 8   destination_airport_id  int64  \n",
      " 9   crs_dep_time            int64  \n",
      " 10  dep_time                float64\n",
      " 11  dep_delay               float64\n",
      " 12  dep_time_blk            object \n",
      " 13  crs_arr_time            int64  \n",
      " 14  arr_time                float64\n",
      " 15  arr_delay_new           float64\n",
      " 16  arr_time_blk            object \n",
      " 17  cancelled               int64  \n",
      " 18  crs_elapsed_time        float64\n",
      " 19  actual_elapsed_time     float64\n",
      " 20  distance                int64  \n",
      " 21  distance_group          int64  \n",
      " 22  year                    int64  \n",
      " 23  carrier_delay           float64\n",
      " 24  weather_delay           float64\n",
      " 25  nas_delay               float64\n",
      " 26  security_delay          float64\n",
      " 27  late_aircraft_delay     float64\n",
      " 28  is_delayed              bool   \n",
      " 29  is_weekend              bool   \n",
      " 30  distance_agg            object \n",
      " 31  manufacture_year        int64  \n",
      " 32  manufacture_year_agg    int64  \n",
      " 33  origin_city_name_x      object \n",
      " 34  origin_airport_id_y     float64\n",
      " 35  origin_city_name_y      object \n",
      "dtypes: bool(2), float64(12), int64(15), object(7)\n",
      "memory usage: 1.8+ GB\n"
     ]
    }
   ],
   "source": [
    "flight_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#zlaczenie kolumn _x oraz _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df['origin_airport_id'] = flight_df['origin_airport_id_x'].fillna(flight_df['origin_airport_id_y'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#usunięcie kolumn _x oraz _y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df.drop(['origin_airport_id_x', 'origin_airport_id_y'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#nadanie odpowiednich nazw kolumnom"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df.rename(columns={'origin_city_name_x': 'origin_city_name'}, inplace=True)\n",
    "flight_df.rename(columns={'origin_city_name_y': 'destination_city_name'}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YOkJOvPDiSsC"
   },
   "source": [
    "### Sprawdzenie\n",
    "Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "6-DKaJV3iSsC"
   },
   "outputs": [],
   "source": [
    "assert 'origin_city_name' in flight_df.columns, 'Brak kolumny `origin_city_name` w ramce flight_df'\n",
    "assert 'destination_city_name' in flight_df.columns, 'Brak kolumny `destination_city_name` w ramce flight_df'\n",
    "\n",
    "flight_df_expected_rows_amount = 6922924\n",
    "assert flight_df.shape[0] == flight_df_expected_rows_amount, 'Ups, zwiększyła się liczba wierszy...'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TM_T8_yUiSsC"
   },
   "source": [
    " ## Analiza według lotnisk oraz tras\n",
    " Wykonaj poniższe polecenia:\n",
    " 1. Wyznacz lotniska, z których **odlatywało** najwięcej samolotów. Wynik zapisz do ramki `top_airports_origin_df`.\n",
    " 1. Wyznacz lotnika, na których najwięcej lotów **się kończyło**. Wynik zapisz do ramki `top_airports_destination_df`.\n",
    " 1. Wyznacz najczęściej uczęszczaną trasę, wynik zapisz do ramki `top_route_df`.\n",
    " 1. Przy założeniu, że reprezentatywna liczba lotów na trasie wynosi ponad 500, wyznacz dodatkowo top 10:\n",
    "     - tras z **najmniejszym odsetkiem opóźnień**, wynik zapisz do ramki `least_route_delays_df`.\n",
    "     - tras z **największym odsetkiem opóźnień**, wynik zapisz do ramki `top_route_delays_df`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dZkT8xQQiSsD"
   },
   "source": [
    " Tutaj wyznacz ramkę `top_airports_origin_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "QdcYfGq0iSsD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>408150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>387620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>294944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>257396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>245160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>11528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Portland, ME</td>\n",
       "      <td>10863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Sanford, FL</td>\n",
       "      <td>10670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kona, HI</td>\n",
       "      <td>9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Lihue, HI</td>\n",
       "      <td>8516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         origin_city_name   count\n",
       "13            Chicago, IL  408150\n",
       "3             Atlanta, GA  387620\n",
       "18  Dallas/Fort Worth, TX  294944\n",
       "55           New York, NY  257396\n",
       "20             Denver, CO  245160\n",
       "..                    ...     ...\n",
       "52        Minneapolis, MN   11528\n",
       "68           Portland, ME   10863\n",
       "82            Sanford, FL   10670\n",
       "39               Kona, HI    9268\n",
       "41              Lihue, HI    8516\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#mój kod\n",
    "\n",
    "top_airports_origin_df = flight_df.groupby('origin_city_name').size().reset_index(name='count')\n",
    "top_airports_origin_df = top_airports_origin_df.sort_values('count', ascending=False)\n",
    "top_airports_origin_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>origin_city_name</th>\n",
       "      <th>top_origin_city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>408150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>387620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>294944</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>257396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>245160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>11528</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Portland, ME</td>\n",
       "      <td>10863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Sanford, FL</td>\n",
       "      <td>10670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kona, HI</td>\n",
       "      <td>9268</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Lihue, HI</td>\n",
       "      <td>8516</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         origin_city_name  top_origin_city\n",
       "13            Chicago, IL           408150\n",
       "3             Atlanta, GA           387620\n",
       "18  Dallas/Fort Worth, TX           294944\n",
       "55           New York, NY           257396\n",
       "20             Denver, CO           245160\n",
       "..                    ...              ...\n",
       "52        Minneapolis, MN            11528\n",
       "68           Portland, ME            10863\n",
       "82            Sanford, FL            10670\n",
       "39               Kona, HI             9268\n",
       "41              Lihue, HI             8516\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kod Marcina - jest identycznie po sort_values!!! :)\n",
    "\n",
    "top_airports_origin_df = flight_df.groupby('origin_city_name').agg({'origin_city_name': 'count'}).rename(columns={'origin_city_name': 'top_origin_city'})\n",
    "top_airports_origin_df = top_airports_origin_df.reset_index(drop=False)\n",
    "top_airports_origin_df.sort_values('top_origin_city', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NspSpmgWiSsD"
   },
   "source": [
    " Tutaj wyznacz ramkę `top_airports_destination_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "PUsGhMxciSsD"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination_city_name</th>\n",
       "      <th>count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>407621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>387542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>294568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>257345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>11575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Portland, ME</td>\n",
       "      <td>10898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Sanford, FL</td>\n",
       "      <td>10658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kona, HI</td>\n",
       "      <td>9277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Lihue, HI</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    destination_city_name   count\n",
       "13            Chicago, IL  407621\n",
       "3             Atlanta, GA  387542\n",
       "18  Dallas/Fort Worth, TX  294568\n",
       "55           New York, NY  257345\n",
       "20             Denver, CO  244898\n",
       "..                    ...     ...\n",
       "52        Minneapolis, MN   11575\n",
       "68           Portland, ME   10898\n",
       "82            Sanford, FL   10658\n",
       "39               Kona, HI    9277\n",
       "41              Lihue, HI    8523\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# mój kod\n",
    "\n",
    "top_airports_destination_df = flight_df.groupby('destination_city_name').size().reset_index(name='count')\n",
    "top_airports_destination_df = top_airports_destination_df.sort_values('count', ascending=False)\n",
    "top_airports_destination_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>destination_city_name</th>\n",
       "      <th>top_airports_destination</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>407621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Atlanta, GA</td>\n",
       "      <td>387542</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Dallas/Fort Worth, TX</td>\n",
       "      <td>294568</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>55</th>\n",
       "      <td>New York, NY</td>\n",
       "      <td>257345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>Denver, CO</td>\n",
       "      <td>244898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52</th>\n",
       "      <td>Minneapolis, MN</td>\n",
       "      <td>11575</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>68</th>\n",
       "      <td>Portland, ME</td>\n",
       "      <td>10898</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Sanford, FL</td>\n",
       "      <td>10658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>Kona, HI</td>\n",
       "      <td>9277</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>Lihue, HI</td>\n",
       "      <td>8523</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>94 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    destination_city_name  top_airports_destination\n",
       "13            Chicago, IL                    407621\n",
       "3             Atlanta, GA                    387542\n",
       "18  Dallas/Fort Worth, TX                    294568\n",
       "55           New York, NY                    257345\n",
       "20             Denver, CO                    244898\n",
       "..                    ...                       ...\n",
       "52        Minneapolis, MN                     11575\n",
       "68           Portland, ME                     10898\n",
       "82            Sanford, FL                     10658\n",
       "39               Kona, HI                      9277\n",
       "41              Lihue, HI                      8523\n",
       "\n",
       "[94 rows x 2 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#kod Marcina - jest identycznie po sort_values!!! :)\n",
    "\n",
    "top_airports_destination_df = flight_df.groupby('destination_city_name').agg({'destination_city_name': 'count'}).rename(columns={'destination_city_name': 'top_airports_destination'})\n",
    "top_airports_destination_df = top_airports_destination_df.reset_index(drop=False)\n",
    "top_airports_destination_df.sort_values('top_airports_destination', ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ipHJ5jBQiSsE"
   },
   "source": [
    " ### Sprawdzenie dla `top_airport_origin`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "HSW0atgsiSsE"
   },
   "outputs": [],
   "source": [
    "# top_airports_origin_head = (top_airports_origin_df\n",
    "#                             .sort_values(ascending=False)\n",
    "#                             .head()\n",
    "#                             .to_list()\n",
    "#                             )\n",
    "# top_airports_origin_head = tuple(top_airports_origin_head)\n",
    "# top_airports_origin_head_expected = (387620, 327647, 294944, 245160, 228415)\n",
    "\n",
    "# assert top_airports_origin_head == top_airports_origin_head_expected, f\"Nie zgadza się top 5 wierszy, oczekiwano wyników: {top_airports_origin_head_expected} otrzymano: {top_airports_origin_head}\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GlET6bUoiSsE"
   },
   "source": [
    "### Sprawdzenie dla `top_airport_destination`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "dPCfyL8kiSsE"
   },
   "outputs": [],
   "source": [
    "# top_airports_destination_head = (top_airports_destination_df\n",
    "#                                  .sort_values(ascending=False)\n",
    "#                                  .head()\n",
    "#                                  .to_list()\n",
    "#                                  )\n",
    "# top_airports_destination_head = tuple(top_airports_destination_head)\n",
    "# top_airports_destination_head_expected = (387542, 327169, 294568, 244898, 227917)\n",
    "\n",
    "# assert top_airports_destination_head == top_airports_destination_head_expected, f\"Nie zgadza się top 5 wierszy, oczekiwano wyników: {top_airports_destination_head_expected} otrzymano: {top_airports_destination_head}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ti3aFTkhiSsF"
   },
   "source": [
    " # Wzbogacenie o dane pogodowe\n",
    " Używając procedury `read_sql_table`, wczytaj tabelę `airport_weather` do ramki `airport_weather_df`. Następnie wykonaj następujące polecenia:\n",
    " 1. Pozostaw w ramce tylko następujące kolumny: `['station', 'name', 'date', 'prcp', 'snow', 'snwd', 'tmax', 'awnd']`.\n",
    " 1. Połącz ramki `airport_list_df` wraz z `airport_weather_df` po odpowiedniej kolumnie używając takiego złączenia, aby w wyniku usunąć te wiersze (lotniska), które nie posiadają danych pogodowych. Dodatkowo, upewnij się, że zostanie tylko dodana kolumna `origin_airport_id`."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "XmM1BAg2iSsF"
   },
   "source": [
    " Tutaj wczytaj ramkę `airport_weather`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "connection = psycopg2.connect(\n",
    "             host='localhost',\n",
    "             user='postgres', \n",
    "             password='p',\n",
    "             dbname='airlines'  \n",
    "             )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "con = connect(host='localhost', database='airlines', user='postgres', password='p')\n",
    "cursor = con.cursor()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "_8K-0UuYiSsF"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46226 entries, 0 to 46225\n",
      "Data columns (total 34 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   id       46226 non-null  int64  \n",
      " 1   wt18     0 non-null      object \n",
      " 2   station  46226 non-null  object \n",
      " 3   name     46226 non-null  object \n",
      " 4   date     46226 non-null  object \n",
      " 5   awnd     45845 non-null  float64\n",
      " 6   prcp     46197 non-null  float64\n",
      " 7   snow     32338 non-null  float64\n",
      " 8   snwd     31750 non-null  float64\n",
      " 9   tavg     34625 non-null  float64\n",
      " 10  tmax     46203 non-null  float64\n",
      " 11  tmin     46200 non-null  float64\n",
      " 12  wdf2     45854 non-null  float64\n",
      " 13  wdf5     45704 non-null  float64\n",
      " 14  wsf2     45854 non-null  float64\n",
      " 15  wsf5     45704 non-null  float64\n",
      " 16  wt01     16798 non-null  float64\n",
      " 17  wt08     5589 non-null   float64\n",
      " 18  wt02     2268 non-null   float64\n",
      " 19  wt03     5085 non-null   float64\n",
      " 20  wt04     362 non-null    float64\n",
      " 21  wt09     316 non-null    float64\n",
      " 22  wt06     522 non-null    float64\n",
      " 23  wt05     146 non-null    float64\n",
      " 24  pgtm     4484 non-null   float64\n",
      " 25  wt10     5 non-null      float64\n",
      " 26  wesd     7 non-null      float64\n",
      " 27  sn32     453 non-null    float64\n",
      " 28  sx32     454 non-null    float64\n",
      " 29  psun     430 non-null    float64\n",
      " 30  tsun     429 non-null    float64\n",
      " 31  tobs     355 non-null    float64\n",
      " 32  wt07     28 non-null     float64\n",
      " 33  wt11     1 non-null      float64\n",
      "dtypes: float64(29), int64(1), object(4)\n",
      "memory usage: 12.0+ MB\n"
     ]
    }
   ],
   "source": [
    "airport_weather_df = read_sql_table('airport_weather')\n",
    "airport_weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UUWJZl4yiSsF"
   },
   "source": [
    " Tutaj oczyść ramkę `airport_weather_df` z nadmiarowych kolumn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "uKoYzdP6iSsF",
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 46226 entries, 0 to 46225\n",
      "Data columns (total 8 columns):\n",
      " #   Column   Non-Null Count  Dtype  \n",
      "---  ------   --------------  -----  \n",
      " 0   station  46226 non-null  object \n",
      " 1   snow     32338 non-null  float64\n",
      " 2   snwd     31750 non-null  float64\n",
      " 3   awnd     45845 non-null  float64\n",
      " 4   date     46226 non-null  object \n",
      " 5   name     46226 non-null  object \n",
      " 6   prcp     46197 non-null  float64\n",
      " 7   tmax     46203 non-null  float64\n",
      "dtypes: float64(5), object(3)\n",
      "memory usage: 2.8+ MB\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5w/n4j85_qn65vg8_tq2dsjly100000gn/T/ipykernel_13215/101230311.py:1: FutureWarning: Passing a set as an indexer is deprecated and will raise in a future version. Use a list instead.\n",
      "  airport_weather_df = airport_weather_df[{'station', 'name', 'date', 'prcp', 'snow', 'snwd', 'tmax', 'awnd'}]\n"
     ]
    }
   ],
   "source": [
    "airport_weather_df = airport_weather_df[{'station', 'name', 'date', 'prcp', 'snow', 'snwd', 'tmax', 'awnd'}]\n",
    "airport_weather_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "OS7fYirxiSsF"
   },
   "source": [
    "Tutaj połącz ramki `airport_list_df` oraz `airport_weather_df` aktualizując `airport_weather_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "MtUutZM-iSsG"
   },
   "outputs": [],
   "source": [
    "airport_weather_df = pd.merge(airport_weather_df, airport_list_df[['name','origin_airport_id']], on='name', how='inner')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Woi9xDUyiSsG"
   },
   "source": [
    " ### Sprawdzenie\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "oJ-Hl8DIiSsG"
   },
   "outputs": [],
   "source": [
    "airport_weather_df_expected_shape = (43394, 9)\n",
    "airport_weather_df_shape = airport_weather_df.shape\n",
    "\n",
    "assert airport_weather_df_expected_shape == airport_weather_df_shape, f'Nieodpowiedni wymiar ramki airport_weather_df, oczekiwano (wierszy, kolumn): {airport_weather_df_expected_shape}'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "84aqKqmqiSsG"
   },
   "source": [
    " ## Połączenie `airport_weather_df` oraz `flight_df`\n",
    " W celu złączenia ramek `airport_weather_df` oraz `flight_df` wykonaj następujące kroki:\n",
    " 1. w ramce `aiport_weather_df` występuje kolumna `date`, zrzutuj ją na typ `DATETIME`.\n",
    " 1. w ramce `flight_df` należy stworzyć nową kolumnę o nazwie `date`. W tym celu:\n",
    " \t- złącz kolumny `month`, `day_of_month` oraz `year` razem, użyj następującego formatu daty: `YYYY-MM-DD`.\n",
    " \t- zrzutuj kolumnę `date` na typ `DATETIME`.\n",
    " 1. złącz ramki używając odpowiedniego klucza, wynik złączenia zapisz do ramki `flight_df`. Uzyj złącznia typu `LEFT JOIN`.\n",
    "\n",
    " > Dlaczego istotne jest zachowanie typów przy złączeniu?\n",
    "\n",
    "W trakcie pracy możesz posłużyć się następującymi artykułami z `LMS`:\n",
    " - `Python - analiza danych > Dzień 6 - Pandas > Merge`\n",
    " - `Python - analiza danych > Dzień 6 - Pandas > Praca z datetime`\n",
    " - Dokumentacje metody `to_datetime`: [klik](https://pandas.pydata.org/docs/reference/api/pandas.to_datetime.html)\n",
    " - Dostępne formaty dat: [klik](https://www.programiz.com/python-programming/datetime/strftime) - sekcja `Format Code List`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3LimbS-niSsG"
   },
   "source": [
    " Tutaj zrzutuj kolumnę `date` na `DATETIME` w ramce `airport_weather_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "SZKRgHq1iSsG"
   },
   "outputs": [],
   "source": [
    "airport_weather_df['date'] = pd.to_datetime(airport_weather_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "99k4j9KSiSsH"
   },
   "source": [
    " Tutaj stwórz kolumnę `date` w ramce `flight_df`. Pamiętaj, aby była ona również typu `DATETIME`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "XtcN9xcxiSsH"
   },
   "outputs": [],
   "source": [
    "flight_df['date'] = pd.to_datetime(flight_df['year'].astype(str) + '-' + flight_df['month'].astype(str) + '-' + flight_df['day_of_month'].astype(str))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df['date'] = pd.to_datetime(flight_df['date'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "joHaF82HiSsH"
   },
   "source": [
    " Tutaj złącz tabele `airport_weather_df` oraz `flight_df`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = flight_df.join(airport_weather_df, on='date', how='left', lsuffix='_flight', rsuffix='_weather')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = pd.merge(airport_weather_df, flight_df, on='origin_airport_id', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# merged_df = pd.merge(airport_weather_df, flight_df, on='date', how='left')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df = flight_df.merge(airport_weather_df, on=['origin_airport_id', 'date'], how='left')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CKYPhq-CiSsH"
   },
   "source": [
    " ### Sprawdzenie\n",
    " Uruchom kod poniżej, aby sprawdzić, czy ta część została poprawnie wykonana"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "ebiyp_5SiSsH"
   },
   "outputs": [],
   "source": [
    "flight_df_expected_rows_amount = 6922924\n",
    "assert flight_df.shape[0] == flight_df_expected_rows_amount, 'Ups, zmieniła się liczba wierszy...'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 6922924 entries, 0 to 6922923\n",
      "Data columns (total 43 columns):\n",
      " #   Column                  Dtype         \n",
      "---  ------                  -----         \n",
      " 0   id                      int64         \n",
      " 1   month                   int64         \n",
      " 2   day_of_month            int64         \n",
      " 3   day_of_week             int64         \n",
      " 4   op_unique_carrier       object        \n",
      " 5   tail_num                object        \n",
      " 6   op_carrier_fl_num       int64         \n",
      " 7   destination_airport_id  int64         \n",
      " 8   crs_dep_time            int64         \n",
      " 9   dep_time                float64       \n",
      " 10  dep_delay               float64       \n",
      " 11  dep_time_blk            object        \n",
      " 12  crs_arr_time            int64         \n",
      " 13  arr_time                float64       \n",
      " 14  arr_delay_new           float64       \n",
      " 15  arr_time_blk            object        \n",
      " 16  cancelled               int64         \n",
      " 17  crs_elapsed_time        float64       \n",
      " 18  actual_elapsed_time     float64       \n",
      " 19  distance                int64         \n",
      " 20  distance_group          int64         \n",
      " 21  year                    int64         \n",
      " 22  carrier_delay           float64       \n",
      " 23  weather_delay           float64       \n",
      " 24  nas_delay               float64       \n",
      " 25  security_delay          float64       \n",
      " 26  late_aircraft_delay     float64       \n",
      " 27  is_delayed              bool          \n",
      " 28  is_weekend              bool          \n",
      " 29  distance_agg            object        \n",
      " 30  manufacture_year        int64         \n",
      " 31  manufacture_year_agg    int64         \n",
      " 32  origin_city_name        object        \n",
      " 33  destination_city_name   object        \n",
      " 34  origin_airport_id       int64         \n",
      " 35  date                    datetime64[ns]\n",
      " 36  station                 object        \n",
      " 37  snow                    float64       \n",
      " 38  snwd                    float64       \n",
      " 39  awnd                    float64       \n",
      " 40  name                    object        \n",
      " 41  prcp                    float64       \n",
      " 42  tmax                    float64       \n",
      "dtypes: bool(2), datetime64[ns](1), float64(16), int64(15), object(9)\n",
      "memory usage: 2.2+ GB\n"
     ]
    }
   ],
   "source": [
    "flight_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "flight_df.to_csv(\"/Users/Me/Desktop/Airports_CL/data/processed/flight_df_03.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FopJHJ3-iSsH"
   },
   "source": [
    " # Praca samodzielna\n",
    " Używając `flight_df` zbadaj następujące hipotezy:\n",
    " 1. Opady śniegu w lotnisku wylotowym wpływają na **wielkość** opóźnienia lotów (kolumna `snow`).\n",
    " 1. Wielkość pokrywy śnieżnej wpływa na **wielkość** opóźnienia lotów (kolumna `snwd`).\n",
    " 1. Temperatura maksymalna wpływa na **wielkość** opóźnienia lotów (kolumna `tmax`).\n",
    " W każdym ćwiczeniu pamiętaj o uwzględnieniu tylko tych zjawisk atmosferycznych, które były zaobserwowane (`>`). Przy wykonywaniu tego zadania masz pełną dowolność.\n",
    "\n",
    "> **Wskazówka:**  \n",
    "> Pamiętaj o tym, aby każda analiza była porównywalna, tj. dokonana przy podobnych założeniach."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ot9M18lXiSsI"
   },
   "source": [
    " ## Analiza dla kolumny `snow`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8Bfo0ZU6iSsI"
   },
   "source": [
    " ### Określenie statystyk opisowych dla kolumny `snow`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "_HYZz1UYiSsI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4224268.00\n",
       "mean           0.05\n",
       "std            0.40\n",
       "min            0.00\n",
       "25%            0.00\n",
       "50%            0.00\n",
       "75%            0.00\n",
       "max           17.20\n",
       "Name: snow, dtype: float64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df['snow'].describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korelacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06597111206830844"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = flight_df['snow'].corr(flight_df['dep_delay'])\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ wynik jest bliski 0, można stwierdzić, że nie ma wystarczających dowodów na liniową zależność między opadami śniegu a opóźnieniami lotów. Oznacza to, że wielkość opóźnień lotów nie jest znacząco zmieniana przez poziom opadów śniegu w lotnisku wylotowym na podstawie dostępnych danych.\n",
    "Nie jest to jednak logiczne, więc potrzebe są dodatkowe analizy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test t-studenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "low_snow_group = flight_df[flight_df['snow'] < threshold]['dep_delay']\n",
    "high_snow_group = flight_df[flight_df['snow'] >= threshold]['dep_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość statystyki t: -91.03941737145492\n",
      "Wartość p: 0.0\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = ttest_ind(low_snow_group, high_snow_group)\n",
    "print(\"Wartość statystyki t:\", t_statistic)\n",
    "print(\"Wartość p:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartość statystyki t wynosząca -91.03941737145492 wskazuje na dużą różnicę między grupami opartymi na poziomach opadów śniegu. Wartość t jest ujemna, co sugeruje, że średnia wartość opóźnień lotów jest istotnie niższa w grupie z wyższymi opadami śniegu w porównaniu do grupy z niższymi opadami śniegu.\n",
    "Innymi słowy - wynik testu t-studenta sugeruje, że opady śniegu w lotnisku wylotowym mają istotny wpływ na wielkość opóźnień lotów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statystyka ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość statystyki F: 6770.506475804289\n",
      "Wartość p: 0.0\n"
     ]
    }
   ],
   "source": [
    "threshold1 = 2  # Próg dla niskich opadów śniegu\n",
    "threshold2 = 5  # Próg dla średnich opadów śniegu\n",
    "\n",
    "# Załóżmy, że mamy trzy grupy: niska, średnia i wysoka opady śniegu\n",
    "low_snow_group = flight_df[flight_df['snow'] < threshold1]['dep_delay']\n",
    "medium_snow_group = flight_df[(flight_df['snow'] >= threshold1) & (flight_df['snow'] < threshold2)]['dep_delay']\n",
    "high_snow_group = flight_df[flight_df['snow'] >= threshold2]['dep_delay']\n",
    "\n",
    "f_statistic, p_value = f_oneway(low_snow_group, medium_snow_group, high_snow_group)\n",
    "print(\"Wartość statystyki F:\", f_statistic)\n",
    "print(\"Wartość p:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statystyka ANOVA swoimi wynikami (wysoki poziom F oraz wartość p: 0) potwierdza hipoteze z testu t-studenta, że opady śniegu w lotnisku wylotowym mają istotny wpływ na wielkość opóźnień lotów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "71em1ElSiSsI"
   },
   "source": [
    " ## Analiza dla kolumny `snwd`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "qZ3XLzuyiSsI"
   },
   "source": [
    " ### Określenie statystyk opisowych dla kolumny `snwd`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "GQbego0SiSsI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    4104447.00\n",
       "mean           0.16\n",
       "std            0.98\n",
       "min            0.00\n",
       "25%            0.00\n",
       "50%            0.00\n",
       "75%            0.00\n",
       "max           25.20\n",
       "Name: snwd, dtype: float64"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df['snwd'].describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korelacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.02638696586790645"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = flight_df['snwd'].corr(flight_df['dep_delay'])\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ wynik jest bliski 0, można stwierdzić, że nie ma wystarczających dowodów na liniową zależność między wielkością pokrywy śnieżnej a opóźnieniami lotów. Oznacza to, że wielkość opóźnień lotów nie jest znacząco zmieniana przez poziom opadów śniegu w lotnisku wylotowym na podstawie dostępnych danych.\n",
    "Nie jest to jednak logiczne, więc potrzebe są dodatkowe analizy."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test t-studenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "low_snwd_group = flight_df[flight_df['snwd'] < threshold]['dep_delay']\n",
    "high_snwd_group = flight_df[flight_df['snwd'] >= threshold]['dep_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość statystyki t: -48.746791464167075\n",
      "Wartość p: 0.0\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = ttest_ind(low_snwd_group, high_snwd_group)\n",
    "print(\"Wartość statystyki t:\", t_statistic)\n",
    "print(\"Wartość p:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Wartość statystyki t wynosząca -48.746791464167075 wskazuje na dużą różnicę między grupami opartymi na poziomach wielkości pokrywy śnieżnej. Wartość t jest ujemna, co sugeruje, że średnia wartość opóźnień lotów jest istotnie niższa w grupie z większą ilością pokrywy śnieżnej w porównaniu do grupy lotnisk z mniejszą pokrywą śnieżną.\n",
    "Innymi słowy - wynik testu t-studenta sugeruje, że wielkość pokrywy śnieżnej na lotnisku wylotowym ma istotny wpływ na wielkość opóźnień lotów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statystyka ANOVA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość statystyki F: 1813.1047538142834\n",
      "Wartość p: 0.0\n"
     ]
    }
   ],
   "source": [
    "threshold1 = 2  # Próg dla niskich opadów śniegu\n",
    "threshold2 = 5  # Próg dla średnich opadów śniegu\n",
    "\n",
    "# Załóżmy, że mamy trzy grupy: niska, średnia i wysoka opady śniegu\n",
    "low_snwd_group = flight_df[flight_df['snwd'] < threshold1]['dep_delay']\n",
    "medium_snwd_group = flight_df[(flight_df['snwd'] >= threshold1) & (flight_df['snwd'] < threshold2)]['dep_delay']\n",
    "high_snwd_group = flight_df[flight_df['snwd'] >= threshold2]['dep_delay']\n",
    "\n",
    "f_statistic, p_value = f_oneway(low_snwd_group, medium_snwd_group, high_snwd_group)\n",
    "print(\"Wartość statystyki F:\", f_statistic)\n",
    "print(\"Wartość p:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statystyka ANOVA swoimi wynikami (wysoki poziom F oraz wartość p: 0) potwierdza hipoteze z testu t-studenta, że wielkość pokrywy śnieżnej na lotnisku wylotowym ma istotny wpływ na wielkość opóźnień lotów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "esT7sp11iSsI"
   },
   "source": [
    " ## Analiza dla kolumny `tmax`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "VhDL12yxiSsI"
   },
   "source": [
    " ### Określenie statystyk opisowych dla kolumny `tmax`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "id": "vAViuWrdiSsJ"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    6211536.00\n",
       "mean          71.42\n",
       "std           18.61\n",
       "min          -13.00\n",
       "25%           59.00\n",
       "50%           74.00\n",
       "75%           86.00\n",
       "max          120.00\n",
       "Name: tmax, dtype: float64"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flight_df['tmax'].describe().round(decimals=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Korelacja"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.0023605385937416883"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "correlation = flight_df['tmax'].corr(flight_df['dep_delay'])\n",
    "correlation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ponieważ wynik jest ujemny, można stwierdzić, że nie istnieje liniowa zależność między maksymalną temperaturą a opóźnieniami lotów. Jednakże jest on bardzo bliski 0, więc dla pewności, poniżej znajduje się dodatkowy test t-studenta"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test t-studenta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "threshold = 5\n",
    "low_tmax_group = flight_df[flight_df['tmax'] < threshold]['dep_delay']\n",
    "high_tmax_group = flight_df[flight_df['tmax'] >= threshold]['dep_delay']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wartość statystyki t: 24.05705085899122\n",
      "Wartość p: 7.139410949553564e-128\n"
     ]
    }
   ],
   "source": [
    "t_statistic, p_value = ttest_ind(low_tmax_group, high_tmax_group)\n",
    "print(\"Wartość statystyki t:\", t_statistic)\n",
    "print(\"Wartość p:\", p_value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Na podstawie wyników testu t-studenta moża wyciagnąć wniosek, że maksymalna termeratura ma znaczący wpływ na opóźnienia lotów."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "B9pXYHV_iSsJ"
   },
   "source": [
    "# Podsumowanie\n",
    "W tej części warsztatu dokonaliśmy kompleksowej analizy posiadanego zbioru danych. Eksploracja\n",
    "pozwoliła nam na zapoznanie się z cechami charakterystycznymi lotów - wiemy już, które \n",
    "zmienne mogą mieć wpływ na opóźnienia lotów, a które nie. Co warto podkreślić, skupiliśmy się na wielu\n",
    "aspektach tej analizy, co otwiera potencjalnie również inne możliwości dalszej pracy nad tą bazą.\n",
    "\n",
    "W tym momencie przejdziemy do kolejnego kroku, w którym, na podstawie tej analizy, przygotujemy \n",
    "system raportowy. Zanim jednak stworzymy dashboard, potrzebujemy zaktualizować naszą bazę danych."
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "136089914e87e2d4f80cd8636e7ceb6fbad42888d13047c5eed4d3dfe8a58423"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
